{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi0LIJtp+g5TJhIjxR1HRa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviel12-coll/JavacTest/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  转 住驻专转 专转"
      ],
      "metadata": {
        "id": "hxp2Maxbh2ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "!pip install huggingface_hub\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install gensim\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade gensim\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "!pip install gensim==4.3.3\n",
        "!pip install pandas matplotlib  scipy==1.13.1\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1R8hNy1kG1v",
        "outputId": "8c3a1d31-7b77-4319-9688-bb7ac8ca8c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m扳>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m扳>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Requirement already satisfied: gensim==4.3.3 in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.3) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.3) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.3) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy==1.13.1 in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy==1.13.1) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9u4SdpCEaozq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y9WXGYuhPDt"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "from huggingface_hub import hf_hub_download\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import KFold\n",
        "from gensim.models import FastText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_path = hf_hub_download(repo_id=\"facebook/fasttext-en-vectors\", filename=\"model.bin\")\n",
        "model = fasttext.load_model(model_path)\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv('test_data_frame.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "iqg1hAuCS9WC",
        "outputId": "9b33af13-e311-4dd2-a9e3-e0687bcccc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a8ccf078-d4c5-42e8-956d-ef8be262d7a5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a8ccf078-d4c5-42e8-956d-ef8be262d7a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_data_frame.csv to test_data_frame (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "注 转  fast text"
      ],
      "metadata": {
        "id": "QfxbzaZSh_bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pre process the data set\n",
        "df = df[df['Response1'].str.strip() != '']\n",
        "df = df[df['Stim'].str.strip() != '']\n",
        "df = df.dropna(subset=['Stim', 'Response1'])\n",
        "\n",
        "\n",
        "condType_dummies = pd.get_dummies(df['condType'], prefix='condType')\n",
        "df = pd.concat([df, condType_dummies], axis=1)\n",
        "# Extract FastText vector for a single word\n",
        "def get_vector(word):\n",
        "  if not isinstance(word, str):\n",
        "      return np.zeros(model.get_dimension())\n",
        "  return model.get_word_vector(word.strip().lower())\n",
        "\n",
        "\n",
        "# Store vectors in separate columns\n",
        "df['Stim_vec'] = df['Stim'].apply(get_vector)\n",
        "df['Response_vec'] = df['Response1'].apply(get_vector)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "df['cosine_sim'] = df.apply(lambda row: cosine_similarity(\n",
        "    [row['Stim_vec']], [row['Response_vec']]\n",
        ")[0][0], axis=1)\n",
        "# Calculate the differnce between two vector\n",
        "df['diff_norm'] = df.apply(lambda row: np.linalg.norm(\n",
        "    row['Stim_vec'] - row['Response_vec']), axis=1)\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2CNbuy7hymy",
        "outputId": "36b7b4b0-9f4d-4c65-f79d-ad0290801d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'subj', 'Stim', 'Response1', 'condType', 'rating',\n",
            "       'condType_Free condition', 'condType_Restricted condition', 'Stim_vec',\n",
            "       'Response_vec', 'cosine_sim', 'diff_norm'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This list will store the fine-tuned cosine results for each fold of each subject\n",
        "cv_results = []\n",
        "\n",
        "# Loop over each subject\n",
        "for subj_id, subj_df in df.groupby('subj'):\n",
        "\n",
        "#remove row that have null\n",
        "    subj_df = subj_df.dropna(subset=['Stim', 'Response1']).reset_index(drop=True)\n",
        "#prepare the word\n",
        "    subj_df['Stim_tok'] = subj_df['Stim'].str.lower().str.split()\n",
        "    subj_df['Resp_tok'] = subj_df['Response1'].str.lower().str.split()\n",
        "\n",
        "    # Create 5-fold cross-validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    subject_results = []\n",
        "\n",
        "\n",
        "# get the train set and the data set\n",
        "    for train_idx, test_idx in kf.split(subj_df):\n",
        "        train_data = subj_df.iloc[train_idx]\n",
        "        test_data = subj_df.iloc[test_idx].copy()\n",
        "\n",
        "        #create row for training\n",
        "        sentences = pd.concat([train_data['Stim_tok'], train_data['Resp_tok']]).tolist()\n",
        "\n",
        "        # Train a FastText model from scratch on this subject's training data\n",
        "        ft_model = FastText(sentences, vector_size=100, window=3, min_count=1, sg=1, epochs=30)\n",
        "        # this function will return the a vector for given word\n",
        "        def get_subject_vec(tokens):\n",
        "            if not tokens:\n",
        "                return np.zeros(100)\n",
        "            return ft_model.wv[tokens[0]]\n",
        "\n",
        "\n",
        "# create a vector for a word for our prariculary model\n",
        "        test_data['Stim_vec_finetuned'] = test_data['Stim_tok'].apply(get_subject_vec)\n",
        "        test_data['Response_vec_finetuned'] = test_data['Resp_tok'].apply(get_subject_vec)\n",
        "\n",
        "# calculate the cosine for every pair word\n",
        "    test_data['cosine_finetuned'] = test_data.apply(\n",
        "              lambda row: cosine_similarity([row['Stim_vec_finetuned']], [row['Response_vec_finetuned']])[0][0],\n",
        "              axis=1\n",
        "          )\n",
        "#\n",
        "    for _, row in test_data.iterrows():\n",
        "                cv_results.append({\n",
        "                    'subj': subj_id,\n",
        "                    'stim': row['Stim'],\n",
        "                    'response': row['Response1'],\n",
        "                    'cosine_baseline': row['cosine_sim'],\n",
        "                    'cosine_finetuned': row['cosine_finetuned'],\n",
        "                    'rating': row['rating']\n",
        "                })\n",
        "\n",
        "#convert to data fame and show the result\n",
        "\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "cv_results_df.head()\n",
        "print(cv_results_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6s5gI6RXrFN",
        "outputId": "0cbf7cc7-7b2d-456b-f92c-027a05382f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      subj    stim  response  cosine_baseline  cosine_finetuned  rating\n",
            "0     S001  Hawaii  sunshine         0.199428          0.094779    1.00\n",
            "1     S001  Impact     force         0.284789         -0.184737    0.77\n",
            "2     S001  Easter     bunny         0.496344         -0.107126    1.00\n",
            "3     S001   Media      film         0.269877          0.044254    1.00\n",
            "4     S001  Inside   outside         0.745039          0.426187    0.98\n",
            "...    ...     ...       ...              ...               ...     ...\n",
            "2046  S062  Burden   trouble         0.270365          0.001013    1.00\n",
            "2047  S062   Black     brown         0.646005         -0.021720    0.00\n",
            "2048  S062  Assume     guess         0.621383         -0.015237    0.00\n",
            "2049  S062  Orange     fruit         0.429627         -0.068246    0.01\n",
            "2050  S062  Sunday   weekend         0.531120         -0.012797    0.01\n",
            "\n",
            "[2051 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the corolation between rating and cosine_baseline and cosine_fineetuned\n",
        "\n",
        "\n",
        "baseline_corr = cv_results_df['cosine_baseline'].corr(cv_results_df['rating'])\n",
        "finetuned_corr = cv_results_df['cosine_finetuned'].corr(cv_results_df['rating'])\n",
        "\n",
        "print(f\" Correlation (baseline): {baseline_corr:.3f}\")\n",
        "print(f\" Correlation (finetuned): {finetuned_corr:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af7QGWzDZqRy",
        "outputId": "003b98b1-37cd-4391-b90f-0c94aa345af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Correlation (baseline): 0.245\n",
            " Correlation (finetuned): -0.018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subject_corrs = cv_results_df.groupby('subj').apply(\n",
        "    lambda g: g['cosine_finetuned'].corr(g['rating'])\n",
        ")\n",
        "\n",
        "print(subject_corrs.sort_values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIBosErWaF3a",
        "outputId": "effa1e5f-01a9-42e2-88ea-668896219092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subj\n",
            "S044   -0.310734\n",
            "S059   -0.265628\n",
            "S041   -0.189918\n",
            "S042   -0.144303\n",
            "S051   -0.138142\n",
            "S030   -0.128676\n",
            "S013   -0.110495\n",
            "S035   -0.101090\n",
            "S061   -0.091530\n",
            "S032   -0.057488\n",
            "S003   -0.052260\n",
            "S009   -0.035535\n",
            "S026   -0.032849\n",
            "S020   -0.019699\n",
            "S010   -0.012056\n",
            "S038   -0.003726\n",
            "S018    0.013945\n",
            "S048    0.030367\n",
            "S043    0.052441\n",
            "S062    0.054152\n",
            "S002    0.068784\n",
            "S016    0.076074\n",
            "S036    0.082483\n",
            "S001    0.090153\n",
            "S045    0.096865\n",
            "S033    0.125242\n",
            "S015    0.131357\n",
            "S046    0.134340\n",
            "S025    0.180966\n",
            "S021    0.215619\n",
            "S060         NaN\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-95f99c72f87b>:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  subject_corrs = cv_results_df.groupby('subj').apply(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will give more wight for row with a good rating"
      ],
      "metadata": {
        "id": "M9GFZG8CbkV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 驻拽爪 爪专转 砖驻 注 砖拽 驻 专\n",
        "#\n",
        "def generate_weighted_sentences(df, scale=5):\n",
        "    sentences = []\n",
        "    for _, row in df.iterrows():\n",
        "        rating = row.get('rating', 1.0)\n",
        "        if pd.isna(rating):\n",
        "            rating = 1.0\n",
        "\n",
        "        norm_rating = rating\n",
        "        weight = norm_rating * scale\n",
        "        # The number of times that the sample will appear.\n",
        "        count = int(np.floor(weight))\n",
        "        prob = weight - count\n",
        "\n",
        "\n",
        "# add the samle count times\n",
        "        for _ in range(count):\n",
        "            sentences.append(row['Stim_tok'])\n",
        "            sentences.append(row['Resp_tok'])\n",
        "\n",
        "        if np.random.rand() < prob:\n",
        "            sentences.append(row['Stim_tok'])\n",
        "            sentences.append(row['Resp_tok'])\n",
        "    return sentences\n",
        "\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "\n",
        "for subj_id, subj_df in df.groupby('subj'):\n",
        "\n",
        "\n",
        "    subj_df = subj_df.dropna(subset=['Stim', 'Response1']).reset_index(drop=True)\n",
        "    subj_df['Stim_tok'] = subj_df['Stim'].str.lower().str.split()\n",
        "    subj_df['Resp_tok'] = subj_df['Response1'].str.lower().str.split()\n",
        "\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for train_idx, test_idx in kf.split(subj_df):\n",
        "        train_data = subj_df.iloc[train_idx]\n",
        "        test_data = subj_df.iloc[test_idx].copy()\n",
        "\n",
        "        # get the row with the generate function\n",
        "        sentences = generate_weighted_sentences(train_data, scale=5)\n",
        "\n",
        "\n",
        "        ft_model = FastText(sentences, vector_size=100, window=3, min_count=1, sg=1, epochs=30)\n",
        "\n",
        "\n",
        "        def get_subject_vec(tokens):\n",
        "            vecs = [ft_model.wv[t] for t in tokens if t in ft_model.wv]\n",
        "            return np.mean(vecs, axis=0) if vecs else np.zeros(100)\n",
        "\n",
        "        test_data['Stim_vec_finetuned'] = test_data['Stim_tok'].apply(get_subject_vec)\n",
        "        test_data['Response_vec_finetuned'] = test_data['Resp_tok'].apply(get_subject_vec)\n",
        "\n",
        "        test_data['cosine_finetuned'] = test_data.apply(\n",
        "            lambda row: cosine_similarity([row['Stim_vec_finetuned']], [row['Response_vec_finetuned']])[0][0],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        for _, row in test_data.iterrows():\n",
        "            cv_results.append({\n",
        "                'subj': subj_id,\n",
        "                'stim': row['Stim'],\n",
        "                'response': row['Response1'],\n",
        "                'cosine_baseline': row['cosine_sim'],\n",
        "                'cosine_finetuned': row['cosine_finetuned'],\n",
        "                'rating': row['rating']\n",
        "            })\n",
        "\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_results)\n"
      ],
      "metadata": {
        "id": "lDf5Po1nbz4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_corr = cv_results_df['cosine_baseline'].corr(cv_results_df['rating'])\n",
        "finetuned_corr = cv_results_df['cosine_finetuned'].corr(cv_results_df['rating'])\n",
        "\n",
        "print(f\" Correlation (baseline): {baseline_corr:.3f}\")\n",
        "print(f\" Correlation (fine-tuned): {finetuned_corr:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu_c9evEb9t7",
        "outputId": "99ed212b-9b97-4960-c8ce-2de657ccead6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Correlation (baseline): 0.224\n",
            " Correlation (fine-tuned): 0.022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "consider typecondition"
      ],
      "metadata": {
        "id": "qcIZo8xAhdN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sJcSZCgk8_8",
        "outputId": "6a8bdf57-6d61-4ee1-8072-c9f398e4e531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unnamed: 0', 'subj', 'Stim', 'Response1', 'condType', 'rating', 'condType_Free condition', 'condType_Restricted condition', 'Stim_vec', 'Response_vec', 'cosine_sim', 'diff_norm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def generate_weighted_sentences(df, scale=5, cond_weight=2.0):\n",
        "    sentences = []\n",
        "    for _, row in df.iterrows():\n",
        "        rating = row.get('rating', 1.0)\n",
        "        if pd.isna(rating):\n",
        "            rating = 1.0\n",
        "\n",
        "\n",
        "        weight = rating * scale\n",
        "\n",
        "\n",
        "        if row.get('condType') == 'Restricted condition':\n",
        "            weight *= cond_weight\n",
        "\n",
        "        count = int(np.floor(weight))\n",
        "        prob = weight - count\n",
        "\n",
        "        for _ in range(count):\n",
        "            sentences.append(row['Stim_tok'])\n",
        "            sentences.append(row['Resp_tok'])\n",
        "\n",
        "        if np.random.rand() < prob:\n",
        "            sentences.append(row['Stim_tok'])\n",
        "            sentences.append(row['Resp_tok'])\n",
        "\n",
        "    return sentences\n",
        "\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "\n",
        "for subj_id, subj_df in df.groupby('subj'):\n",
        "    subj_df = subj_df.dropna(subset=['Stim', 'Response1']).reset_index(drop=True)\n",
        "\n",
        "\n",
        "    subj_df['Stim_tok'] = subj_df['Stim'].str.lower().str.split()\n",
        "    subj_df['Resp_tok'] = subj_df['Response1'].str.lower().str.split()\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for train_idx, test_idx in kf.split(subj_df):\n",
        "        train_data = subj_df.iloc[train_idx]\n",
        "        test_data = subj_df.iloc[test_idx].copy()\n",
        "\n",
        "\n",
        "        sentences = generate_weighted_sentences(train_data, scale=5, cond_weight=2.0)\n",
        "\n",
        "\n",
        "        ft_model = FastText(sentences, vector_size=100, window=3, min_count=1, sg=1, epochs=30)\n",
        "\n",
        "\n",
        "        def get_subject_vec(tokens):\n",
        "            vecs = [ft_model.wv[t] for t in tokens if t in ft_model.wv]\n",
        "            return np.mean(vecs, axis=0) if vecs else np.zeros(100)\n",
        "\n",
        "        test_data['Stim_vec_finetuned'] = test_data['Stim_tok'].apply(get_subject_vec)\n",
        "        test_data['Response_vec_finetuned'] = test_data['Resp_tok'].apply(get_subject_vec)\n",
        "\n",
        "        test_data['cosine_finetuned'] = test_data.apply(\n",
        "            lambda row: cosine_similarity([row['Stim_vec_finetuned']], [row['Response_vec_finetuned']])[0][0],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        for _, row in test_data.iterrows():\n",
        "            cv_results.append({\n",
        "                'subj': subj_id,\n",
        "                'stim': row['Stim'],\n",
        "                'response': row['Response1'],\n",
        "                'cosine_baseline': row.get('cosine_sim', np.nan),  # 专拽  砖  注 \n",
        "                'cosine_finetuned': row['cosine_finetuned'],\n",
        "                'rating': row['rating'],\n",
        "                'condType': row.get('condType', None)\n",
        "            })\n",
        "\n",
        "# 爪专转 DataFrame 转爪转\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "\n",
        "# 转爪 专砖转\n",
        "cv_results_df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KZeulI4Qhcka",
        "outputId": "0f324815-299b-4228-9ef3-d08018c70116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   subj    stim  response  cosine_baseline  cosine_finetuned  rating  \\\n",
              "0  S001   Floor    carpet         0.467344          0.040308    1.00   \n",
              "1  S001    Made   product         0.137407          0.062516    0.77   \n",
              "2  S001   After    before         0.770152          0.026930    1.00   \n",
              "3  S001  Europe   hungary         0.621839          0.036269    1.00   \n",
              "4  S001    Vote  election         0.556339         -0.137208    1.00   \n",
              "\n",
              "         condType  \n",
              "0  Free condition  \n",
              "1  Free condition  \n",
              "2  Free condition  \n",
              "3  Free condition  \n",
              "4  Free condition  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-954e0960-d2d8-4be8-8eda-6f4c1db497c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subj</th>\n",
              "      <th>stim</th>\n",
              "      <th>response</th>\n",
              "      <th>cosine_baseline</th>\n",
              "      <th>cosine_finetuned</th>\n",
              "      <th>rating</th>\n",
              "      <th>condType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S001</td>\n",
              "      <td>Floor</td>\n",
              "      <td>carpet</td>\n",
              "      <td>0.467344</td>\n",
              "      <td>0.040308</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Free condition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S001</td>\n",
              "      <td>Made</td>\n",
              "      <td>product</td>\n",
              "      <td>0.137407</td>\n",
              "      <td>0.062516</td>\n",
              "      <td>0.77</td>\n",
              "      <td>Free condition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S001</td>\n",
              "      <td>After</td>\n",
              "      <td>before</td>\n",
              "      <td>0.770152</td>\n",
              "      <td>0.026930</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Free condition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S001</td>\n",
              "      <td>Europe</td>\n",
              "      <td>hungary</td>\n",
              "      <td>0.621839</td>\n",
              "      <td>0.036269</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Free condition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S001</td>\n",
              "      <td>Vote</td>\n",
              "      <td>election</td>\n",
              "      <td>0.556339</td>\n",
              "      <td>-0.137208</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Free condition</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-954e0960-d2d8-4be8-8eda-6f4c1db497c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-954e0960-d2d8-4be8-8eda-6f4c1db497c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-954e0960-d2d8-4be8-8eda-6f4c1db497c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cbb2fb80-f0a9-4327-9204-c6a5cc173998\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cbb2fb80-f0a9-4327-9204-c6a5cc173998')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cbb2fb80-f0a9-4327-9204-c6a5cc173998 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cv_results_df",
              "summary": "{\n  \"name\": \"cv_results_df\",\n  \"rows\": 10297,\n  \"fields\": [\n    {\n      \"column\": \"subj\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"S059\",\n          \"S033\",\n          \"S045\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stim\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"Year\",\n          \"Pieces\",\n          \"Knight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2488,\n        \"samples\": [\n          \"decent\",\n          \"aware\",\n          \"kill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cosine_baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19340427653507636,\n        \"min\": -0.05855746567249298,\n        \"max\": 1.000000238418579,\n        \"num_unique_values\": 4438,\n        \"samples\": [\n          0.13809216022491455,\n          0.3118334412574768,\n          0.3681604266166687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cosine_finetuned\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14991612574741459,\n        \"min\": -0.36912301182746887,\n        \"max\": 1.000000238418579,\n        \"num_unique_values\": 7842,\n        \"samples\": [\n          -0.11931347846984863,\n          -0.06875142455101013,\n          0.044713083654642105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2809524736145232,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.4,\n          0.64,\n          0.23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"condType\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Restricted condition\",\n          \"Free condition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "211cA-PbCxiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "P47J_xcRnfr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "csv_path = '/content/drive/MyDrive/cv_results.csv'\n",
        "cv_results_df.to_csv(csv_path, index=False)\n",
        "print(f\" Results saved to: {csv_path}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnbO1ZPQidHr",
        "outputId": "08ed9226-8398-4a78-dc62-7f43df37437f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Results saved to: /content/drive/MyDrive/cv_results.csv\n"
          ]
        }
      ]
    }
  ]
}